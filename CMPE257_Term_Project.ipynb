{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d857eaea",
      "metadata": {
        "id": "d857eaea"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d8e66440",
      "metadata": {
        "id": "d8e66440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe5b4f2-089c-43ef-c59d-12de565b2d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "data = yf.download('BTC-USD', start=\"2014-09-17\", end=\"2024-05-19\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ccdc64a9",
      "metadata": {
        "id": "ccdc64a9"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data[['High', 'Low', 'Close']].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d021ecfd",
      "metadata": {
        "id": "d021ecfd"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-time_step):\n",
        "        dataX.append(dataset[i:(i+time_step), :])\n",
        "        dataY.append(dataset[i + time_step, :])\n",
        "    return np.array(dataX), np.array(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = 30\n",
        "dataX, datay = create_dataset(data_scaled, time_step)"
      ],
      "metadata": {
        "id": "jyGcAGJdIwpU"
      },
      "id": "jyGcAGJdIwpU",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataX, datay, test_size = 0.1, random_state=42)"
      ],
      "metadata": {
        "id": "NaMS5TjdI79H"
      },
      "id": "NaMS5TjdI79H",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "d4d55007",
      "metadata": {
        "id": "d4d55007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0035779c-9f85-454d-dd39-fb781e847022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (3150, 30, 3)\n",
            "X_test:  (351, 30, 3)\n"
          ]
        }
      ],
      "source": [
        "x_train =x_train.reshape(x_train.shape[0],x_train.shape[1] , 3) #sample, time step, features\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 3)\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"X_test: \", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8b592485",
      "metadata": {
        "id": "8b592485"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, activation='gelu', dropout=0.0, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "    model.add(LSTM(64, activation='gelu', dropout=0.2))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32))\n",
        "    model.add(Dense(3))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e3a918a2",
      "metadata": {
        "id": "e3a918a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466a49d4-7ba4-4be4-f766-39664fc545da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 30, 128)           67584     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,331\n",
            "Trainable params: 123,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_lstm_model()\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "    loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ad6f39a1",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad6f39a1",
        "outputId": "b9807aca-8a11-4422-a6a5-9920caa70767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "99/99 [==============================] - 18s 115ms/step - loss: 0.0147 - val_loss: 9.2530e-04\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 9s 88ms/step - loss: 8.5665e-04 - val_loss: 0.0014\n",
            "Epoch 3/100\n",
            "99/99 [==============================] - 12s 126ms/step - loss: 8.4867e-04 - val_loss: 9.3700e-04\n",
            "Epoch 4/100\n",
            "99/99 [==============================] - 12s 126ms/step - loss: 7.6500e-04 - val_loss: 7.6607e-04\n",
            "Epoch 5/100\n",
            "99/99 [==============================] - 11s 114ms/step - loss: 7.6966e-04 - val_loss: 0.0012\n",
            "Epoch 6/100\n",
            "99/99 [==============================] - 9s 92ms/step - loss: 7.1468e-04 - val_loss: 8.7699e-04\n",
            "Epoch 7/100\n",
            "99/99 [==============================] - 11s 106ms/step - loss: 6.0445e-04 - val_loss: 5.7705e-04\n",
            "Epoch 8/100\n",
            "99/99 [==============================] - 12s 120ms/step - loss: 5.7711e-04 - val_loss: 5.1415e-04\n",
            "Epoch 9/100\n",
            "99/99 [==============================] - 13s 128ms/step - loss: 6.6801e-04 - val_loss: 4.7296e-04\n",
            "Epoch 10/100\n",
            "99/99 [==============================] - 10s 97ms/step - loss: 5.1081e-04 - val_loss: 4.0985e-04\n",
            "Epoch 11/100\n",
            "99/99 [==============================] - 9s 95ms/step - loss: 5.0677e-04 - val_loss: 4.4699e-04\n",
            "Epoch 12/100\n",
            "99/99 [==============================] - 11s 106ms/step - loss: 5.0652e-04 - val_loss: 3.5947e-04\n",
            "Epoch 13/100\n",
            "99/99 [==============================] - 10s 104ms/step - loss: 4.3013e-04 - val_loss: 3.5585e-04\n",
            "Epoch 14/100\n",
            "99/99 [==============================] - 9s 86ms/step - loss: 4.7969e-04 - val_loss: 2.9245e-04\n",
            "Epoch 15/100\n",
            "99/99 [==============================] - 11s 112ms/step - loss: 3.9629e-04 - val_loss: 3.2002e-04\n",
            "Epoch 16/100\n",
            "99/99 [==============================] - 10s 104ms/step - loss: 4.4691e-04 - val_loss: 4.1862e-04\n",
            "Epoch 17/100\n",
            "99/99 [==============================] - 8s 86ms/step - loss: 4.2516e-04 - val_loss: 4.4231e-04\n",
            "Epoch 18/100\n",
            "99/99 [==============================] - 10s 106ms/step - loss: 3.7839e-04 - val_loss: 2.2105e-04\n",
            "Epoch 19/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 4.0337e-04 - val_loss: 2.1867e-04\n",
            "Epoch 20/100\n",
            "99/99 [==============================] - 9s 91ms/step - loss: 4.0016e-04 - val_loss: 2.5288e-04\n",
            "Epoch 21/100\n",
            "99/99 [==============================] - 10s 102ms/step - loss: 3.2920e-04 - val_loss: 2.1903e-04\n",
            "Epoch 22/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 3.0987e-04 - val_loss: 2.7592e-04\n",
            "Epoch 23/100\n",
            "99/99 [==============================] - 10s 99ms/step - loss: 3.3771e-04 - val_loss: 3.8452e-04\n",
            "Epoch 24/100\n",
            "99/99 [==============================] - 9s 94ms/step - loss: 3.2761e-04 - val_loss: 5.9731e-04\n",
            "Epoch 25/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 3.4584e-04 - val_loss: 3.0654e-04\n",
            "Epoch 26/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 3.1275e-04 - val_loss: 2.5443e-04\n",
            "Epoch 27/100\n",
            "99/99 [==============================] - 9s 86ms/step - loss: 3.5864e-04 - val_loss: 2.2831e-04\n",
            "Epoch 28/100\n",
            "99/99 [==============================] - 10s 106ms/step - loss: 3.1424e-04 - val_loss: 2.7234e-04\n",
            "Epoch 29/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.8119e-04 - val_loss: 2.0343e-04\n",
            "Epoch 30/100\n",
            "99/99 [==============================] - 9s 87ms/step - loss: 2.6509e-04 - val_loss: 1.4128e-04\n",
            "Epoch 31/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.4688e-04 - val_loss: 1.7361e-04\n",
            "Epoch 32/100\n",
            "99/99 [==============================] - 11s 112ms/step - loss: 2.7511e-04 - val_loss: 1.3859e-04\n",
            "Epoch 33/100\n",
            "99/99 [==============================] - 9s 94ms/step - loss: 2.6151e-04 - val_loss: 3.0006e-04\n",
            "Epoch 34/100\n",
            "99/99 [==============================] - 10s 99ms/step - loss: 3.0130e-04 - val_loss: 1.5566e-04\n",
            "Epoch 35/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.8567e-04 - val_loss: 1.6005e-04\n",
            "Epoch 36/100\n",
            "99/99 [==============================] - 10s 104ms/step - loss: 2.7773e-04 - val_loss: 1.3218e-04\n",
            "Epoch 37/100\n",
            "99/99 [==============================] - 9s 88ms/step - loss: 2.6073e-04 - val_loss: 1.8957e-04\n",
            "Epoch 38/100\n",
            "99/99 [==============================] - 11s 110ms/step - loss: 2.4127e-04 - val_loss: 2.4178e-04\n",
            "Epoch 39/100\n",
            "99/99 [==============================] - 11s 109ms/step - loss: 2.3555e-04 - val_loss: 1.7933e-04\n",
            "Epoch 40/100\n",
            "99/99 [==============================] - 13s 133ms/step - loss: 2.4575e-04 - val_loss: 2.1448e-04\n",
            "Epoch 41/100\n",
            "99/99 [==============================] - 13s 129ms/step - loss: 2.9400e-04 - val_loss: 1.9279e-04\n",
            "Epoch 42/100\n",
            "99/99 [==============================] - 15s 152ms/step - loss: 3.4270e-04 - val_loss: 1.8321e-04\n",
            "Epoch 43/100\n",
            "99/99 [==============================] - 16s 159ms/step - loss: 2.7946e-04 - val_loss: 1.3250e-04\n",
            "Epoch 44/100\n",
            "99/99 [==============================] - 13s 128ms/step - loss: 2.3826e-04 - val_loss: 1.1366e-04\n",
            "Epoch 45/100\n",
            "99/99 [==============================] - 13s 132ms/step - loss: 2.4550e-04 - val_loss: 1.2068e-04\n",
            "Epoch 46/100\n",
            "99/99 [==============================] - 14s 143ms/step - loss: 2.3167e-04 - val_loss: 1.4249e-04\n",
            "Epoch 47/100\n",
            "99/99 [==============================] - 12s 119ms/step - loss: 2.1687e-04 - val_loss: 2.6411e-04\n",
            "Epoch 48/100\n",
            "99/99 [==============================] - 13s 132ms/step - loss: 2.6087e-04 - val_loss: 1.0871e-04\n",
            "Epoch 49/100\n",
            "99/99 [==============================] - 11s 115ms/step - loss: 2.8709e-04 - val_loss: 1.9081e-04\n",
            "Epoch 50/100\n",
            "99/99 [==============================] - 14s 146ms/step - loss: 2.8698e-04 - val_loss: 1.4583e-04\n",
            "Epoch 51/100\n",
            "99/99 [==============================] - 9s 87ms/step - loss: 2.3403e-04 - val_loss: 1.6963e-04\n",
            "Epoch 52/100\n",
            "99/99 [==============================] - 11s 116ms/step - loss: 2.2362e-04 - val_loss: 1.2013e-04\n",
            "Epoch 53/100\n",
            "99/99 [==============================] - 14s 143ms/step - loss: 2.3548e-04 - val_loss: 1.4675e-04\n",
            "Epoch 54/100\n",
            "99/99 [==============================] - 17s 177ms/step - loss: 2.2858e-04 - val_loss: 2.8705e-04\n",
            "Epoch 55/100\n",
            "99/99 [==============================] - 13s 130ms/step - loss: 2.0878e-04 - val_loss: 1.6085e-04\n",
            "Epoch 56/100\n",
            "99/99 [==============================] - 11s 115ms/step - loss: 2.1852e-04 - val_loss: 1.2523e-04\n",
            "Epoch 57/100\n",
            "99/99 [==============================] - 9s 91ms/step - loss: 2.1492e-04 - val_loss: 1.6258e-04\n",
            "Epoch 58/100\n",
            "99/99 [==============================] - 10s 102ms/step - loss: 2.2697e-04 - val_loss: 1.1998e-04\n",
            "Epoch 59/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.2749e-04 - val_loss: 1.1027e-04\n",
            "Epoch 60/100\n",
            "99/99 [==============================] - 10s 100ms/step - loss: 2.2683e-04 - val_loss: 1.2764e-04\n",
            "Epoch 61/100\n",
            "99/99 [==============================] - 10s 103ms/step - loss: 2.0994e-04 - val_loss: 1.1005e-04\n",
            "Epoch 62/100\n",
            "99/99 [==============================] - 11s 109ms/step - loss: 1.9352e-04 - val_loss: 1.2126e-04\n",
            "Epoch 63/100\n",
            "99/99 [==============================] - 11s 109ms/step - loss: 2.0859e-04 - val_loss: 1.2393e-04\n",
            "Epoch 64/100\n",
            "99/99 [==============================] - 11s 110ms/step - loss: 2.5315e-04 - val_loss: 2.0568e-04\n",
            "Epoch 65/100\n",
            "99/99 [==============================] - 11s 110ms/step - loss: 2.0041e-04 - val_loss: 2.4156e-04\n",
            "Epoch 66/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.1728e-04 - val_loss: 1.1884e-04\n",
            "Epoch 67/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.0752e-04 - val_loss: 1.4910e-04\n",
            "Epoch 68/100\n",
            "99/99 [==============================] - 9s 87ms/step - loss: 2.1012e-04 - val_loss: 1.6262e-04\n",
            "Epoch 69/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.2524e-04 - val_loss: 1.3896e-04\n",
            "Epoch 70/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.0790e-04 - val_loss: 1.7129e-04\n",
            "Epoch 71/100\n",
            "99/99 [==============================] - 9s 86ms/step - loss: 1.8033e-04 - val_loss: 1.8506e-04\n",
            "Epoch 72/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.1193e-04 - val_loss: 1.1969e-04\n",
            "Epoch 73/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 1.9493e-04 - val_loss: 1.0139e-04\n",
            "Epoch 74/100\n",
            "99/99 [==============================] - 10s 100ms/step - loss: 2.1452e-04 - val_loss: 1.0190e-04\n",
            "Epoch 75/100\n",
            "99/99 [==============================] - 10s 100ms/step - loss: 2.1297e-04 - val_loss: 1.0305e-04\n",
            "Epoch 76/100\n",
            "99/99 [==============================] - 10s 105ms/step - loss: 1.9601e-04 - val_loss: 1.4699e-04\n",
            "Epoch 77/100\n",
            "99/99 [==============================] - 10s 99ms/step - loss: 1.7479e-04 - val_loss: 1.0059e-04\n",
            "Epoch 78/100\n",
            "99/99 [==============================] - 9s 93ms/step - loss: 2.0694e-04 - val_loss: 1.4186e-04\n",
            "Epoch 79/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.1533e-04 - val_loss: 1.3819e-04\n",
            "Epoch 80/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.4495e-04 - val_loss: 1.6368e-04\n",
            "Epoch 81/100\n",
            "99/99 [==============================] - 9s 86ms/step - loss: 2.0432e-04 - val_loss: 1.5463e-04\n",
            "Epoch 82/100\n",
            "99/99 [==============================] - 11s 109ms/step - loss: 2.1695e-04 - val_loss: 1.8263e-04\n",
            "Epoch 83/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 1.7576e-04 - val_loss: 1.0602e-04\n",
            "Epoch 84/100\n",
            "99/99 [==============================] - 9s 87ms/step - loss: 1.6956e-04 - val_loss: 1.2119e-04\n",
            "Epoch 85/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 1.9247e-04 - val_loss: 1.1462e-04\n",
            "Epoch 86/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.0519e-04 - val_loss: 3.3924e-04\n",
            "Epoch 87/100\n",
            "99/99 [==============================] - 9s 92ms/step - loss: 1.9403e-04 - val_loss: 1.0951e-04\n",
            "Epoch 88/100\n",
            "99/99 [==============================] - 10s 102ms/step - loss: 1.7444e-04 - val_loss: 1.1845e-04\n",
            "Epoch 89/100\n",
            "99/99 [==============================] - 11s 109ms/step - loss: 1.7222e-04 - val_loss: 1.5916e-04\n",
            "Epoch 90/100\n",
            "99/99 [==============================] - 10s 99ms/step - loss: 1.7893e-04 - val_loss: 1.1230e-04\n",
            "Epoch 91/100\n",
            "99/99 [==============================] - 10s 96ms/step - loss: 1.7964e-04 - val_loss: 1.1072e-04\n",
            "Epoch 92/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.1900e-04 - val_loss: 9.7269e-05\n",
            "Epoch 93/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.0707e-04 - val_loss: 1.2553e-04\n",
            "Epoch 94/100\n",
            "99/99 [==============================] - 9s 86ms/step - loss: 1.6955e-04 - val_loss: 1.1441e-04\n",
            "Epoch 95/100\n",
            "99/99 [==============================] - 11s 108ms/step - loss: 2.0312e-04 - val_loss: 3.4485e-04\n",
            "Epoch 96/100\n",
            "99/99 [==============================] - 11s 107ms/step - loss: 2.0665e-04 - val_loss: 1.1364e-04\n",
            "Epoch 97/100\n",
            "99/99 [==============================] - 9s 88ms/step - loss: 2.0446e-04 - val_loss: 1.0019e-04\n",
            "Epoch 98/100\n",
            "99/99 [==============================] - 10s 106ms/step - loss: 2.0321e-04 - val_loss: 2.7795e-04\n",
            "Epoch 99/100\n",
            "99/99 [==============================] - 11s 110ms/step - loss: 1.8765e-04 - val_loss: 1.1233e-04\n",
            "Epoch 100/100\n",
            "99/99 [==============================] - 9s 94ms/step - loss: 1.8306e-04 - val_loss: 1.1504e-04\n"
          ]
        }
      ],
      "source": [
        "checkpoint_filepath = 'model_{epoch}.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_weights_only = True,\n",
        "    monitor = 'val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "model_earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience = 10,\n",
        "    verbose = 1, #shows message whnen callback takes an action\n",
        "    mode = 'min',\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "history = model.fit(x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_test,y_test),\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    callbacks = [model_checkpoint_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.keras\")"
      ],
      "metadata": {
        "id": "RHeY0hn4qCs2"
      },
      "id": "RHeY0hn4qCs2",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "095db419",
      "metadata": {
        "id": "095db419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13a3301-2bba-4c6b-d8ed-7c130c678c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 3s 26ms/step\n",
            "0.00012861760575866524\n",
            "676402.9950016916\n"
          ]
        }
      ],
      "source": [
        "training_prediction = model.predict(x_train)\n",
        "train_score = mean_squared_error(y_train, training_prediction)\n",
        "train_score_unscaled = mean_squared_error(scaler.inverse_transform(y_train), scaler.inverse_transform(training_prediction))\n",
        "print(train_score)\n",
        "print(train_score_unscaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "23867dd2",
      "metadata": {
        "id": "23867dd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7238d680-1107-4906-dc03-1e8698c1e3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 24ms/step\n",
            "0.00011503550238739137\n",
            "605627.5606942744\n"
          ]
        }
      ],
      "source": [
        "test_prediction = model.predict(x_test)\n",
        "test_score = mean_squared_error(y_test, test_prediction)\n",
        "test_score_unscaled = mean_squared_error(scaler.inverse_transform(y_test), scaler.inverse_transform(test_prediction))\n",
        "print(test_score)\n",
        "print(test_score_unscaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "c338f7a4",
      "metadata": {
        "id": "c338f7a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972e11f4-2556-4fcf-c71d-f37eee04bd12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9978796336344445\n",
            "0.998076771691968\n"
          ]
        }
      ],
      "source": [
        "#r-2 score\n",
        "train_r2 = r2_score(scaler.inverse_transform(training_prediction), (scaler.inverse_transform(y_train)))\n",
        "print(train_r2)\n",
        "test_r2 = r2_score(scaler.inverse_transform(test_prediction), (scaler.inverse_transform(y_test)))\n",
        "print(test_r2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czHOYfJangND"
      },
      "id": "czHOYfJangND",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}